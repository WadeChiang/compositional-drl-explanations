{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove useless neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DQN64'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from settings import NET_NAME\n",
    "\n",
    "NET_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "mean_iou = {}\n",
    "i = 5\n",
    "res = pd.read_csv(f\"../save/LunarLander-{NET_NAME}/result_{i}.csv\")\n",
    "res = res[res[\"iou\"] > 0]\n",
    "res = res.sort_values(by=\"iou\", ascending=False)\n",
    "mean_iou[i] = res[\"iou\"].mean()\n",
    "res.to_csv(f\"../save/LunarLander-{NET_NAME}/result_{i}_parsed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "find 4 outputs top connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({1002, 236, 623}, {325, 555, 844, 205, 475, 606, 415}, {288, 673, 902, 652, 367, 212, 341, 316}, {609, 494, 242, 440, 24, 318}) \n",
      "\n",
      "  763 0.30485895\n",
      "  302 0.28758878\n",
      "  986 0.2645894\n",
      "  643 0.25234053\n",
      "  237 0.24664687\n",
      "  706 0.21200533\n",
      "  885 0.20753646\n",
      "  279 0.20324802\n",
      "  903 0.19172496\n",
      "* 1002 0.16097532\n",
      "  142 0.13872454\n",
      "  368 0.13216262\n",
      "  1007 0.104875065\n",
      "  831 0.10194893\n",
      "* 623 0.09671927\n",
      "  488 0.09349492\n",
      "* 236 0.08687392\n",
      "  589 0.062169034\n",
      "  468 0.061411772\n",
      "  192 0.05901481\n",
      "  763 0.3922268\n",
      "* 555 0.3755717\n",
      "  142 0.3370697\n",
      "  589 0.3358096\n",
      "  825 0.29140386\n",
      "  706 0.22679016\n",
      "  718 0.20479837\n",
      "  302 0.19379257\n",
      "  854 0.19233328\n",
      "* 415 0.19211861\n",
      "  569 0.14957115\n",
      "* 205 0.14751582\n",
      "  643 0.12503086\n",
      "* 475 0.11712325\n",
      "  167 0.10907171\n",
      "* 606 0.09092694\n",
      "* 325 0.081854574\n",
      "  831 0.07968554\n",
      "  108 0.07887353\n",
      "* 844 0.067143545\n",
      "* 341 0.58988327\n",
      "* 212 0.55288494\n",
      "  854 0.4673015\n",
      "* 902 0.41630557\n",
      "  885 0.30716595\n",
      "  108 0.21929523\n",
      "  109 0.18448631\n",
      "  279 0.17271154\n",
      "  368 0.14518444\n",
      "* 316 0.14097175\n",
      "  406 0.11672783\n",
      "* 367 0.114570335\n",
      "* 652 0.098929375\n",
      "  488 0.09145716\n",
      "  167 0.08190771\n",
      "  192 0.066844776\n",
      "* 673 0.06120608\n",
      "  110 0.057059415\n",
      "  825 0.05487946\n",
      "* 288 0.053106155\n",
      "* 494 0.44458404\n",
      "  718 0.3432757\n",
      "  109 0.3123336\n",
      "  237 0.28999335\n",
      "  903 0.2862867\n",
      "  1007 0.2723025\n",
      "  406 0.24759717\n",
      "  986 0.24582347\n",
      "  488 0.19836359\n",
      "  167 0.17279604\n",
      "  569 0.12956321\n",
      "* 318 0.11323928\n",
      "  108 0.10623786\n",
      "  110 0.098471485\n",
      "  763 0.09242477\n",
      "* 440 0.088693395\n",
      "* 609 0.07861648\n",
      "  468 0.073424965\n",
      "* 24 0.07340578\n",
      "* 242 0.065750994\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "i = 5\n",
    "N = 20\n",
    "csv = pd.read_csv(f\"../save/LunarLander-{NET_NAME}/result_{i}_parsed.csv\")\n",
    "output_file = f\"../save/LunarLander-{NET_NAME}/output_{i}.txt\"\n",
    "neurons = []\n",
    "\n",
    "\n",
    "def find_unique_elements(arr1, arr2, arr3, arr4):\n",
    "    set1, set2, set3, set4 = set(arr1), set(arr2), set(arr3), set(arr4)\n",
    "    unique1 = set1 - set2 - set3 - set4\n",
    "    unique2 = set2 - set1 - set3 - set4\n",
    "    unique3 = set3 - set1 - set2 - set4\n",
    "    unique4 = set4 - set1 - set2 - set3\n",
    "\n",
    "    return unique1, unique2, unique3, unique4\n",
    "\n",
    "\n",
    "for label in [\"w_nothing\", \"w_left\", \"w_main\", \"w_right\"]:\n",
    "    sorted_csv = csv.sort_values(by=label, ascending=False)\n",
    "    top_neurons = sorted_csv.head(N)[\"neuron\"].tolist()\n",
    "    neurons.append(top_neurons)\n",
    "\n",
    "unique_elements = find_unique_elements(neurons[0], neurons[1], neurons[2], neurons[3])\n",
    "print(unique_elements, \"\\n\")\n",
    "\n",
    "with open(output_file, \"w\") as f:\n",
    "    for i, label in enumerate([\"w_nothing\", \"w_left\", \"w_main\", \"w_right\"]):\n",
    "        csv = csv.sort_values(by=label, ascending=False)\n",
    "        top_neurons = csv.head(N)[[\"neuron\", label]].to_records(index=False)\n",
    "        print(f\"\\n============\\n{label} top {N}:\", file=f)\n",
    "        for neuron, value in top_neurons:\n",
    "            if neuron in unique_elements[i]:\n",
    "                print(f\"* {neuron} {value}\", file=f)  # Special mark for unique elements\n",
    "                print(f\"* {neuron} {value}\")\n",
    "            else:\n",
    "                print(f\"  {neuron} {value}\", file=f)\n",
    "                print(f\"  {neuron} {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "find act & inp pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 3 3 ... 1 1 1]\n",
      "(10000,)\n",
      "(1715,)\n",
      "(2127,)\n",
      "(2696,)\n",
      "(3462,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "act = np.load(f\"../save/LunarLander-{NET_NAME}/actions.npy\")\n",
    "obs = np.load(\"../save/lunar.npy\")\n",
    "\n",
    "act_list = []\n",
    "act_idx_list = []\n",
    "max_indices = np.argmax(act, axis=1)\n",
    "print(max_indices)\n",
    "print(max_indices.shape)\n",
    "for i in range(4):\n",
    "    max_row_index = np.where(max_indices == i)[0]\n",
    "    print(max_row_index.shape)\n",
    "    # max_row = act[max_row_index]\n",
    "    act_idx_list.append(max_row_index)\n",
    "    act_list.append(obs[max_row_index])\n",
    "\n",
    "# np.save(f'../save/LunarLander-{NET_NAME}/max_indices.npy', max_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## analyze specific neuron(DQN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load model and dataset\n",
      "Extract features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:00<00:00, 419.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing quantiles\n",
      "Generating atomic masks\n",
      "(10000, 16)\n"
     ]
    }
   ],
   "source": [
    "from analyze import *\n",
    "\n",
    "ckpt_path = \"../save/ckpt-mlp1024-260.pth\"\n",
    "data_path = \"../save/lunar.npy\"\n",
    "print(\"Load model and dataset\")\n",
    "model, dataset = load_for_analysis(ckpt_path, data_path)\n",
    "weights = model.fc3.weight.t().detach().cpu().numpy()\n",
    "\n",
    "print(\"Extract features\")\n",
    "inputs, features, outputs = extract_feature(model, dataset)\n",
    "outputs = np.array(outputs)\n",
    "if not os.path.exists(settings.RESULT):\n",
    "    # 如果不存在，创建路径\n",
    "    os.makedirs(settings.RESULT)\n",
    "np.save(os.path.join(settings.RESULT, f\"actions.npy\"), outputs)\n",
    "print(\"Computing quantiles\")\n",
    "activations = quantile_features(features)\n",
    "print(\"Generating atomic masks\")\n",
    "feat_masks = gen_feat_mask(inputs)\n",
    "print(feat_masks.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[x, y, Vx, Vy, angle, angular_v, l, r]\n",
    "\n",
    "y_near_ground: <0.4\n",
    "\n",
    "Vy_low: -0.5 ~ 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1237,)\n",
      "[54.300285 52.586964 50.26787  52.025227]\n",
      "[ 0.30821085  0.35956365  1.         -0.44264442  0.39747119 -0.08431965\n",
      "  0.          0.        ]\n",
      "0.63623697\n",
      "[ 0.30821085  0.35956365  1.         -0.44264442  0.39747119 -0.08431965\n",
      "  0.          0.        ]\n",
      "[array([0., 0., 0., ..., 0., 0., 0.], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "def intersect(x: np.ndarray, y: np.ndarray):\n",
    "    return np.array(list(set(x).intersection(set(y))))\n",
    "\n",
    "\n",
    "vy_low = np.where(feat_masks[:, 7] > 0)[0]\n",
    "y_near_ground = np.where(feat_masks[:, 4] > 0)[0]\n",
    "\n",
    "vy_low_and_y_near_ground = intersect(vy_low, y_near_ground)\n",
    "\n",
    "neuron_act = np.where(activations[:, 630] > 0)[0]\n",
    "res = intersect(neuron_act, act_idx_list[0])\n",
    "res = intersect(res, vy_low_and_y_near_ground)\n",
    "print(res.shape)\n",
    "print(act[res[10]])\n",
    "print(obs[res[10]])\n",
    "print(features[res[10]][630])\n",
    "hook = HookLayer()\n",
    "hook.hook_layer(layer=model.act2)\n",
    "obs_attk = obs[res[10]]\n",
    "obs_attk[2] = 1.0\n",
    "print(obs_attk)\n",
    "act_attk = model(torch.tensor(obs_attk, dtype=torch.float32).to(settings.DEVICE))\n",
    "print(hook.features_blobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "tensor([88.7608, 86.5204, 93.6968, 86.7465], device='cuda:3',\n",
      "       grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(hook.features_blobs[0][630])\n",
    "print(act_attk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## analyze attack (PPO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load model and dataset\n",
      "Computing quantiles\n",
      "Generating atomic masks\n",
      "(10000, 16)\n"
     ]
    }
   ],
   "source": [
    "from PPO import get_PPO\n",
    "import settings\n",
    "from analyze import *\n",
    "\n",
    "ckpt_path = \"../save/LunarLander-PPO1024/ppo.pth\"\n",
    "data_path = \"../save/lunar.npy\"\n",
    "print(\"Load model and dataset\")\n",
    "inputs, features, outputs, weight, policy = get_PPO(ckpt_path, data_path)\n",
    "\n",
    "\n",
    "if not os.path.exists(settings.RESULT):\n",
    "    # 如果不存在，创建路径\n",
    "    os.makedirs(settings.RESULT)\n",
    "np.save(os.path.join(settings.RESULT, f\"actions.npy\"), outputs)\n",
    "print(\"Computing quantiles\")\n",
    "activations = quantile_features(features)\n",
    "print(\"Generating atomic masks\")\n",
    "feat_masks = gen_feat_mask(inputs)\n",
    "print(feat_masks.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14,)\n",
      "[0.28012165 0.15548752 0.48146957 0.0829213 ]\n",
      "[ 0.9         0.01810535  1.         -0.2070954   0.21621577 -0.67224586\n",
      "  1.          1.        ]\n",
      "0.37163532\n",
      "[[ 0.9         0.01810535  1.         -0.2070954   0.21621577 -0.67224586\n",
      "   1.          1.        ]]\n",
      "(1, 8)\n",
      "-1.70284\n",
      "Batch(\n",
      "    logits: tensor([[1.2064e-01, 8.7784e-01, 1.1213e-03, 3.9262e-04]], device='cuda:3',\n",
      "                   grad_fn=<SoftmaxBackward0>),\n",
      "    act: tensor([1], device='cuda:3'),\n",
      "    state: None,\n",
      "    dist: Categorical(probs: torch.Size([1, 4])),\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import tianshou\n",
    "\n",
    "\n",
    "def intersect(x: np.ndarray, y: np.ndarray):\n",
    "    return np.array(list(set(x).intersection(set(y))))\n",
    "\n",
    "\n",
    "not_l_leg = np.where(feat_masks[:, 14] == 0)[0]\n",
    "r_leg = np.where(feat_masks[:, 15] > 0)[0]\n",
    "x_in_centor = np.where(feat_masks[:, 0] > 0)[0]\n",
    "\n",
    "inter = intersect(not_l_leg, r_leg)\n",
    "inter = intersect(x_in_centor, inter)\n",
    "\n",
    "neuron_act = np.where(activations[:, 212] > 0)[0]\n",
    "res = intersect(neuron_act, act_idx_list[2])\n",
    "res = intersect(res, inter)\n",
    "print(res.shape)\n",
    "print(act[res[10]])\n",
    "print(obs[res[10]])\n",
    "print(features[res[10]][212])\n",
    "hook = HookLayer()\n",
    "hook.hook_layer(policy.actor.preprocess.model.model[2])\n",
    "obs_attk = obs[res[10]]\n",
    "obs_attk[0] = 0.9\n",
    "obs_attk[6] = 1.0\n",
    "obs_attk = obs_attk.reshape(1, -1)\n",
    "print(obs_attk)\n",
    "print(obs_attk.shape)\n",
    "act_attk = policy(tianshou.data.Batch(obs=obs_attk, info=\"\"))\n",
    "print(hook.features_blobs[0][0][212])\n",
    "print(act_attk)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
