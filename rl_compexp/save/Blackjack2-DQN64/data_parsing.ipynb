{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove useless neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.hooks.RemovableHandle at 0x7f3961682d50>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "from tianshou.data import Collector, VectorReplayBuffer, Batch\n",
    "from tianshou.utils.net.common import Net\n",
    "from gymnasium.wrappers import TransformObservation\n",
    "from tianshou.env import SubprocVectorEnv\n",
    "from tianshou.policy import DQNPolicy\n",
    "import pprint\n",
    "\n",
    "weights = np.load('weights.npy')\n",
    "hiddens = np.load('hidden_outputs.npy')\n",
    "actions = np.load('actions.npy')\n",
    "states = np.load('states.npy')\n",
    "def make_env():\n",
    "    env = gym.make(\"Blackjack-v1\", natural=False, sab=False)\n",
    "    env = TransformObservation(env, lambda obs: np.array(obs), observation_space=None)\n",
    "    return env\n",
    "\n",
    "\n",
    "DEVICE = \"cuda:0\"\n",
    "env = make_env()\n",
    "state_shape = 3\n",
    "action_shape = env.action_space.shape or env.action_space.n\n",
    "\n",
    "q_net = Net(state_shape, action_shape, hidden_sizes=[64] * 2, device=DEVICE).to(DEVICE)\n",
    "optim = torch.optim.Adam(q_net.parameters(), lr=2.5e-4)\n",
    "policy = DQNPolicy(\n",
    "    model=q_net,\n",
    "    optim=optim,\n",
    "    action_space=env.action_space,\n",
    "    discount_factor=0.99,\n",
    "    estimation_step=3,\n",
    "    target_update_freq=500,\n",
    ").to(DEVICE)\n",
    "policy.eval()\n",
    "checkpoint_path = \"/root/gym/rl_compexp/save/Blackjack2-DQN64/dqn_best.pth\"\n",
    "policy.load_state_dict(torch.load(checkpoint_path,map_location=DEVICE))\n",
    "hidden_outputs = []\n",
    "def hook_fn(module, input, output):\n",
    "    # Assuming output is a tensor, detach and move to CPU\n",
    "    hidden_outputs.append(output.detach().cpu().numpy())\n",
    "\n",
    "\n",
    "policy.model.model.model[2].register_forward_hook(hook_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4462, 3)\n",
      "origin action: 0, origin state: [20  9  0], origin hidden:2.0437397956848145\n",
      "purt action: 1, purt state: [14  9  0], purt hidden:-1.0301517248153687\n"
     ]
    }
   ],
   "source": [
    "neuron = 28\n",
    "index = hiddens[:,neuron]>0\n",
    "\n",
    "selected_states = states[index]\n",
    "print(selected_states.shape)\n",
    "selected_actions = actions[index]\n",
    "selected_hidden_outputs = hiddens[index]\n",
    "concept = \"((((P18 OR P20) OR P19) OR P17) OR P21)\"\n",
    "# for i in range(10):\n",
    "#     state = selected_states[i]\n",
    "#     act0 = policy(Batch(obs=state.reshape(1, -1), info=\"\")).act.item()\n",
    "# print(f\"origin action: {act0}, origin state: {state}, origin hidden:{hidden_outputs[-1][0,neuron]}\")\n",
    "origin_state = selected_states[1]\n",
    "act0 = policy(Batch(obs=origin_state.reshape(1, -1), info=\"\")).act.item()\n",
    "print(f\"origin action: {act0}, origin state: {origin_state}, origin hidden:{hidden_outputs[-1][0,neuron]}\")\n",
    "\n",
    "purt_state = selected_states[1].copy()\n",
    "purt_state[0] = 14\n",
    "act1 = policy(Batch(obs=purt_state.reshape(1, -1), info=\"\")).act.item()\n",
    "print(f\"purt action: {act1}, purt state: {purt_state}, purt hidden:{hidden_outputs[-1][0,neuron]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1349, 3)\n",
      "origin action: 1, origin state: [6 9 0], origin hidden:2.0420312881469727\n",
      "purt action: 0, purt state: [17  9  0], purt hidden:-6.891425132751465\n"
     ]
    }
   ],
   "source": [
    "neuron = 13\n",
    "index = hiddens[:,neuron]>0\n",
    "\n",
    "selected_states = states[index]\n",
    "print(selected_states.shape)\n",
    "selected_actions = actions[index]\n",
    "selected_hidden_outputs = hiddens[index]\n",
    "concept = \"P6-P10\"\n",
    "# for i in range(10):\n",
    "#     state = selected_states[i]\n",
    "#     act0 = policy(Batch(obs=state.reshape(1, -1), info=\"\")).act.item()\n",
    "#     print(f\"origin action: {act0}, origin state: {state}, origin hidden:{hidden_outputs[-1][0,neuron]}\")\n",
    "i=0\n",
    "origin_state = selected_states[i]\n",
    "act0 = policy(Batch(obs=origin_state.reshape(1, -1), info=\"\")).act.item()\n",
    "print(f\"origin action: {act0}, origin state: {origin_state}, origin hidden:{hidden_outputs[-1][0,neuron]}\")\n",
    "\n",
    "purt_state = selected_states[i].copy()\n",
    "purt_state[0] = 17\n",
    "act1 = policy(Batch(obs=purt_state.reshape(1, -1), info=\"\")).act.item()\n",
    "print(f\"purt action: {act1}, purt state: {purt_state}, purt hidden:{hidden_outputs[-1][0,neuron]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5828, 3)\n",
      "origin action: 1, origin state: [15  9  0], origin hidden:1.069049596786499\n",
      "purt action: 0, purt state: [15  5  0], purt hidden:-0.9205737113952637\n"
     ]
    }
   ],
   "source": [
    "neuron = 17\n",
    "index = hiddens[:,neuron]>0\n",
    "\n",
    "selected_states = states[index]\n",
    "print(selected_states.shape)\n",
    "selected_actions = actions[index]\n",
    "selected_hidden_outputs = hiddens[index]\n",
    "concept = \"D7-D10\"\n",
    "# for i in range(10):\n",
    "#     state = selected_states[i]\n",
    "#     act0 = policy(Batch(obs=state.reshape(1, -1), info=\"\")).act.item()\n",
    "#     print(f\"origin action: {act0}, origin state: {state}, origin hidden:{hidden_outputs[-1][0,neuron]}\")\n",
    "i=1\n",
    "origin_state = selected_states[i]\n",
    "act0 = policy(Batch(obs=origin_state.reshape(1, -1), info=\"\")).act.item()\n",
    "print(f\"origin action: {act0}, origin state: {origin_state}, origin hidden:{hidden_outputs[-1][0,neuron]}\")\n",
    "\n",
    "purt_state = selected_states[i].copy()\n",
    "purt_state[1] = 5\n",
    "act1 = policy(Batch(obs=purt_state.reshape(1, -1), info=\"\")).act.item()\n",
    "print(f\"purt action: {act1}, purt state: {purt_state}, purt hidden:{hidden_outputs[-1][0,neuron]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取排序后的索引\n",
    "sorted_indices = np.argsort(weights, axis=0)[::-1]\n",
    "\n",
    "# 根据索引获取排序后的值\n",
    "sorted_weights = np.take_along_axis(weights, sorted_indices, axis=0)\n",
    "\n",
    "print(sorted_indices)\n",
    "print(sorted_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "mean_iou = {}\n",
    "i = 5\n",
    "res = pd.read_csv(f\"result_{i}.csv\")\n",
    "res = res[res[\"iou\"] > 0]\n",
    "res = res.sort_values(by=\"iou\", ascending=False)\n",
    "mean_iou[i] = res[\"iou\"].mean()\n",
    "res.to_csv(f\"result_{i}_parsed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "find 4 outputs top connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "i = 5\n",
    "N = 10\n",
    "csv = pd.read_csv(f\"result_{i}_parsed.csv\")\n",
    "output_file = f\"output_{i}.txt\"\n",
    "neurons = []\n",
    "\n",
    "\n",
    "def find_unique_elements(arr1, arr2):\n",
    "    set1, set2,  = set(arr1), set(arr2)\n",
    "    unique1 = set1 - set2 \n",
    "    unique2 = set2 - set1 \n",
    "\n",
    "\n",
    "    return unique1, unique2\n",
    "\n",
    "\n",
    "for label in [\"w_stick\",\"w_hit\"]:\n",
    "    sorted_csv = csv.sort_values(by=label, ascending=False)\n",
    "    top_neurons = sorted_csv.head(N)[\"neuron\"].tolist()\n",
    "    neurons.append(top_neurons)\n",
    "\n",
    "unique_elements = find_unique_elements(neurons[0], neurons[1])\n",
    "print(unique_elements, \"\\n\")\n",
    "\n",
    "with open(output_file, \"w\") as f:\n",
    "    for i, label in enumerate([\"w_stick\", \"w_hit\"]):\n",
    "        csv = csv.sort_values(by=label, ascending=False)\n",
    "        top_neurons = csv.head(N)[[\"neuron\", label]].to_records(index=False)\n",
    "        print(f\"\\n============\\n{label} top {N}:\", file=f)\n",
    "        for neuron, value in top_neurons:\n",
    "            if neuron in unique_elements[i]:\n",
    "                print(f\"* {neuron} {value}\", file=f)  # Special mark for unique elements\n",
    "                print(f\"* {neuron} {value}\")\n",
    "            else:\n",
    "                print(f\"  {neuron} {value}\", file=f)\n",
    "                print(f\"  {neuron} {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "find act & inp pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "act = np.load(f\"../save/LunarLander-{NET_NAME}/actions.npy\")\n",
    "obs = np.load(\"../save/lunar.npy\")\n",
    "\n",
    "act_list = []\n",
    "act_idx_list = []\n",
    "max_indices = np.argmax(act, axis=1)\n",
    "print(max_indices)\n",
    "print(max_indices.shape)\n",
    "for i in range(4):\n",
    "    max_row_index = np.where(max_indices == i)[0]\n",
    "    print(max_row_index.shape)\n",
    "    # max_row = act[max_row_index]\n",
    "    act_idx_list.append(max_row_index)\n",
    "    act_list.append(obs[max_row_index])\n",
    "\n",
    "# np.save(f'../save/LunarLander-{NET_NAME}/max_indices.npy', max_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## analyze specific neuron(DQN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analyze import *\n",
    "\n",
    "ckpt_path = \"../save/ckpt-mlp1024-260.pth\"\n",
    "data_path = \"../save/lunar.npy\"\n",
    "print(\"Load model and dataset\")\n",
    "model, dataset = load_for_analysis(ckpt_path, data_path)\n",
    "weights = model.fc3.weight.t().detach().cpu().numpy()\n",
    "\n",
    "print(\"Extract features\")\n",
    "inputs, features, outputs = extract_feature(model, dataset)\n",
    "outputs = np.array(outputs)\n",
    "if not os.path.exists(settings.RESULT):\n",
    "    # 如果不存在，创建路径\n",
    "    os.makedirs(settings.RESULT)\n",
    "np.save(os.path.join(settings.RESULT, f\"actions.npy\"), outputs)\n",
    "print(\"Computing quantiles\")\n",
    "activations = quantile_features(features)\n",
    "print(\"Generating atomic masks\")\n",
    "feat_masks = gen_feat_mask(inputs)\n",
    "print(feat_masks.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[x, y, Vx, Vy, angle, angular_v, l, r]\n",
    "\n",
    "y_near_ground: <0.4\n",
    "\n",
    "Vy_low: -0.5 ~ 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersect(x: np.ndarray, y: np.ndarray):\n",
    "    return np.array(list(set(x).intersection(set(y))))\n",
    "\n",
    "\n",
    "vy_low = np.where(feat_masks[:, 7] > 0)[0]\n",
    "y_near_ground = np.where(feat_masks[:, 4] > 0)[0]\n",
    "\n",
    "vy_low_and_y_near_ground = intersect(vy_low, y_near_ground)\n",
    "\n",
    "neuron_act = np.where(activations[:, 630] > 0)[0]\n",
    "res = intersect(neuron_act, act_idx_list[0])\n",
    "res = intersect(res, vy_low_and_y_near_ground)\n",
    "print(res.shape)\n",
    "print(act[res[10]])\n",
    "print(obs[res[10]])\n",
    "print(features[res[10]][630])\n",
    "hook = HookLayer()\n",
    "hook.hook_layer(layer=model.act2)\n",
    "obs_attk = obs[res[10]]\n",
    "obs_attk[2] = 1.0\n",
    "print(obs_attk)\n",
    "act_attk = model(torch.tensor(obs_attk, dtype=torch.float32).to(settings.DEVICE))\n",
    "print(hook.features_blobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hook.features_blobs[0][630])\n",
    "print(act_attk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## analyze attack (PPO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PPO import get_PPO\n",
    "import settings\n",
    "from analyze import *\n",
    "\n",
    "ckpt_path = \"../save/LunarLander-PPO1024/ppo.pth\"\n",
    "data_path = \"../save/lunar.npy\"\n",
    "print(\"Load model and dataset\")\n",
    "inputs, features, outputs, weight, policy = get_PPO(ckpt_path, data_path)\n",
    "\n",
    "\n",
    "if not os.path.exists(settings.RESULT):\n",
    "    # 如果不存在，创建路径\n",
    "    os.makedirs(settings.RESULT)\n",
    "np.save(os.path.join(settings.RESULT, f\"actions.npy\"), outputs)\n",
    "print(\"Computing quantiles\")\n",
    "activations = quantile_features(features)\n",
    "print(\"Generating atomic masks\")\n",
    "feat_masks = gen_feat_mask(inputs)\n",
    "print(feat_masks.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tianshou\n",
    "\n",
    "\n",
    "def intersect(x: np.ndarray, y: np.ndarray):\n",
    "    return np.array(list(set(x).intersection(set(y))))\n",
    "\n",
    "\n",
    "not_l_leg = np.where(feat_masks[:, 14] == 0)[0]\n",
    "r_leg = np.where(feat_masks[:, 15] > 0)[0]\n",
    "x_in_centor = np.where(feat_masks[:, 0] > 0)[0]\n",
    "\n",
    "inter = intersect(not_l_leg, r_leg)\n",
    "inter = intersect(x_in_centor, inter)\n",
    "\n",
    "neuron_act = np.where(activations[:, 212] > 0)[0]\n",
    "res = intersect(neuron_act, act_idx_list[2])\n",
    "res = intersect(res, inter)\n",
    "print(res.shape)\n",
    "print(act[res[10]])\n",
    "print(obs[res[10]])\n",
    "print(features[res[10]][212])\n",
    "hook = HookLayer()\n",
    "hook.hook_layer(policy.actor.preprocess.model.model[2])\n",
    "obs_attk = obs[res[10]]\n",
    "obs_attk[0] = 0.9\n",
    "obs_attk[6] = 1.0\n",
    "obs_attk = obs_attk.reshape(1, -1)\n",
    "print(obs_attk)\n",
    "print(obs_attk.shape)\n",
    "act_attk = policy(tianshou.data.Batch(obs=obs_attk, info=\"\"))\n",
    "print(hook.features_blobs[0][0][212])\n",
    "print(act_attk)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
